{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-02T07:44:13.374765Z",
     "iopub.status.busy": "2025-03-02T07:44:13.374460Z",
     "iopub.status.idle": "2025-03-02T07:44:32.168344Z",
     "shell.execute_reply": "2025-03-02T07:44:32.167591Z",
     "shell.execute_reply.started": "2025-03-02T07:44:13.374736Z"
    }
   },
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T20:14:12.853423Z",
     "iopub.status.busy": "2025-04-05T20:14:12.852937Z",
     "iopub.status.idle": "2025-04-05T20:14:15.653287Z",
     "shell.execute_reply": "2025-04-05T20:14:15.652200Z",
     "shell.execute_reply.started": "2025-04-05T20:14:12.853377Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GScream'...\n",
      "remote: Enumerating objects: 1819, done.\u001b[K\n",
      "remote: Counting objects: 100% (1819/1819), done.\u001b[K\n",
      "remote: Compressing objects: 100% (921/921), done.\u001b[K\n",
      "remote: Total 1819 (delta 927), reused 1690 (delta 866), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (1819/1819), 39.80 MiB | 29.66 MiB/s, done.\n",
      "Resolving deltas: 100% (927/927), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/gulshanhatzade/GScream.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T20:14:15.655092Z",
     "iopub.status.busy": "2025-04-05T20:14:15.654790Z",
     "iopub.status.idle": "2025-04-05T20:14:15.659455Z",
     "shell.execute_reply": "2025-04-05T20:14:15.658288Z",
     "shell.execute_reply.started": "2025-04-05T20:14:15.655055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# mv /kaggle/input/code-w102-n4/GScream /kaggle/working/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T20:14:15.662076Z",
     "iopub.status.busy": "2025-04-05T20:14:15.661717Z",
     "iopub.status.idle": "2025-04-05T20:14:15.686598Z",
     "shell.execute_reply": "2025-04-05T20:14:15.685685Z",
     "shell.execute_reply.started": "2025-04-05T20:14:15.662049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/GScream\n"
     ]
    }
   ],
   "source": [
    "%cd GScream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T20:14:15.688748Z",
     "iopub.status.busy": "2025-04-05T20:14:15.688368Z",
     "iopub.status.idle": "2025-04-05T20:30:22.638383Z",
     "shell.execute_reply": "2025-04-05T20:30:22.637221Z",
     "shell.execute_reply.started": "2025-04-05T20:14:15.688712Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting appdirs==1.4.4\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting bidirectional-cross-attention==0.0.4\n",
      "  Downloading bidirectional_cross_attention-0.0.4-py3-none-any.whl.metadata (685 bytes)\n",
      "Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
      "Requirement already satisfied: colorama==0.4.6 in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
      "Collecting cycler==0.11.0\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl.metadata (785 bytes)\n",
      "Requirement already satisfied: docker-pycreds==0.4.0 in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
      "Collecting einops==0.6.1\n",
      "  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting fonttools==4.38.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl.metadata (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: gitdb==4.0.11 in /usr/local/lib/python3.10/dist-packages (4.0.11)\n",
      "Collecting gitpython==3.1.41\n",
      "  Downloading GitPython-3.1.41-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting importlib-metadata==6.7.0\n",
      "  Downloading importlib_metadata-6.7.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting jaxtyping==0.2.12\n",
      "  Downloading jaxtyping-0.2.12-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting joblib==1.3.2\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting kornia==0.6.12\n",
      "  Downloading kornia-0.6.12-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting lpips==0.1.4\n",
      "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting matplotlib==3.5.3\n",
      "  Downloading matplotlib-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting opencv-python==4.9.0.80\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting packaging==23.2\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting plyfile==0.8.1\n",
      "  Downloading plyfile-0.8.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting prettytable==3.7.0\n",
      "  Downloading prettytable-3.7.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting protobuf==4.24.4\n",
      "  Downloading protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
      "Collecting psutil==5.9.7\n",
      "  Downloading psutil-5.9.7-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting pyparsing==3.1.1\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting python-dateutil==2.8.2\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting pytorch-fid==0.3.0\n",
      "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyyaml==6.0.1\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting scikit-learn==1.0.2\n",
      "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting scipy==1.7.3\n",
      "  Downloading scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting sentry-sdk==1.39.2\n",
      "  Downloading sentry_sdk-1.39.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting setproctitle==1.3.3\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Collecting six==1.16.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: smmap==5.0.1 in /usr/local/lib/python3.10/dist-packages (5.0.1)\n",
      "Collecting threadpoolctl==3.1.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting torch-scatter==2.1.1\n",
      "  Downloading torch_scatter-2.1.1.tar.gz (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting tqdm==4.66.1\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typeguard==4.1.2\n",
      "  Downloading typeguard-4.1.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wandb==0.16.2\n",
      "  Downloading wandb-0.16.2-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /usr/local/lib/python3.10/dist-packages (0.2.13)\n",
      "Collecting zipp==3.15.0\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from bidirectional-cross-attention==0.0.4) (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from jaxtyping==0.2.12) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping==0.2.12) (4.12.2)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lpips==0.1.4) (0.20.1+cu121)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (11.0.0)\n",
      "Collecting numpy>=1.20.0 (from jaxtyping==0.2.12)\n",
      "  Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from sentry-sdk==1.39.2) (2025.1.31)\n",
      "Requirement already satisfied: urllib3>=1.26.11 in /usr/local/lib/python3.10/dist-packages (from sentry-sdk==1.39.2) (2.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.2) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.2) (75.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.16.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.16.2) (3.10)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->bidirectional-cross-attention==0.0.4) (3.17.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->bidirectional-cross-attention==0.0.4) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->bidirectional-cross-attention==0.0.4) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->bidirectional-cross-attention==0.0.4) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->bidirectional-cross-attention==0.0.4) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6->bidirectional-cross-attention==0.0.4) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->bidirectional-cross-attention==0.0.4) (3.0.2)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading bidirectional_cross_attention-0.0.4-py3-none-any.whl (4.1 kB)\n",
      "Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading jaxtyping-0.2.12-py3-none-any.whl (19 kB)\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kornia-0.6.12-py2.py3-none-any.whl (653 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.4/653.4 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading plyfile-0.8.1-py3-none-any.whl (28 kB)\n",
      "Downloading prettytable-3.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psutil-5.9.7-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (285 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.5/285.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-1.39.2-py2.py3-none-any.whl (254 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typeguard-4.1.2-py3-none-any.whl (33 kB)\n",
      "Downloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: torch-scatter\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-scatter: filename=torch_scatter-2.1.1-cp310-cp310-linux_x86_64.whl size=3656706 sha256=6ae4315725ca12ab7ff7162f8fee45ff4d8f956a0cd004b015889a7114573150\n",
      "  Stored in directory: /root/.cache/pip/wheels/ef/67/58/6566a3b61c6ec0f2ca0c2c324cd035ef2955601f0fb3197d5f\n",
      "Successfully built torch-scatter\n",
      "Installing collected packages: appdirs, zipp, typeguard, tqdm, torch-scatter, threadpoolctl, six, setproctitle, sentry-sdk, pyyaml, pyparsing, psutil, protobuf, prettytable, packaging, numpy, joblib, fonttools, einops, cycler, scipy, python-dateutil, plyfile, opencv-python, jaxtyping, importlib-metadata, gitpython, wandb, scikit-learn, matplotlib, kornia, bidirectional-cross-attention, pytorch-fid, lpips\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.21.0\n",
      "    Uninstalling zipp-3.21.0:\n",
      "      Successfully uninstalled zipp-3.21.0\n",
      "  Attempting uninstall: typeguard\n",
      "    Found existing installation: typeguard 4.4.1\n",
      "    Uninstalling typeguard-4.4.1:\n",
      "      Successfully uninstalled typeguard-4.4.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.5.0\n",
      "    Uninstalling threadpoolctl-3.5.0:\n",
      "      Successfully uninstalled threadpoolctl-3.5.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.17.0\n",
      "    Uninstalling six-1.17.0:\n",
      "      Successfully uninstalled six-1.17.0\n",
      "  Attempting uninstall: setproctitle\n",
      "    Found existing installation: setproctitle 1.3.4\n",
      "    Uninstalling setproctitle-1.3.4:\n",
      "      Successfully uninstalled setproctitle-1.3.4\n",
      "  Attempting uninstall: sentry-sdk\n",
      "    Found existing installation: sentry-sdk 2.19.2\n",
      "    Uninstalling sentry-sdk-2.19.2:\n",
      "      Successfully uninstalled sentry-sdk-2.19.2\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.2.0\n",
      "    Uninstalling pyparsing-3.2.0:\n",
      "      Successfully uninstalled pyparsing-3.2.0\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.5\n",
      "    Uninstalling psutil-5.9.5:\n",
      "      Successfully uninstalled psutil-5.9.5\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: prettytable\n",
      "    Found existing installation: prettytable 3.12.0\n",
      "    Uninstalling prettytable-3.12.0:\n",
      "      Successfully uninstalled prettytable-3.12.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.4.2\n",
      "    Uninstalling joblib-1.4.2:\n",
      "      Successfully uninstalled joblib-1.4.2\n",
      "  Attempting uninstall: fonttools\n",
      "    Found existing installation: fonttools 4.55.3\n",
      "    Uninstalling fonttools-4.55.3:\n",
      "      Successfully uninstalled fonttools-4.55.3\n",
      "  Attempting uninstall: einops\n",
      "    Found existing installation: einops 0.8.0\n",
      "    Uninstalling einops-0.8.0:\n",
      "      Successfully uninstalled einops-0.8.0\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.12.1\n",
      "    Uninstalling cycler-0.12.1:\n",
      "      Successfully uninstalled cycler-0.12.1\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.13.1\n",
      "    Uninstalling scipy-1.13.1:\n",
      "      Successfully uninstalled scipy-1.13.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.10.0.84\n",
      "    Uninstalling opencv-python-4.10.0.84:\n",
      "      Successfully uninstalled opencv-python-4.10.0.84\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib_metadata 8.5.0\n",
      "    Uninstalling importlib_metadata-8.5.0:\n",
      "      Successfully uninstalled importlib_metadata-8.5.0\n",
      "  Attempting uninstall: gitpython\n",
      "    Found existing installation: GitPython 3.1.43\n",
      "    Uninstalling GitPython-3.1.43:\n",
      "      Successfully uninstalled GitPython-3.1.43\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.19.1\n",
      "    Uninstalling wandb-0.19.1:\n",
      "      Successfully uninstalled wandb-0.19.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.5\n",
      "    Uninstalling matplotlib-3.7.5:\n",
      "      Successfully uninstalled matplotlib-3.7.5\n",
      "  Attempting uninstall: kornia\n",
      "    Found existing installation: kornia 0.8.0\n",
      "    Uninstalling kornia-0.8.0:\n",
      "      Successfully uninstalled kornia-0.8.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cartopy 0.24.1 requires matplotlib>=3.6, but you have matplotlib 3.5.3 which is incompatible.\n",
      "cartopy 0.24.1 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.1 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.0.0 which is incompatible.\n",
      "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.22.4 which is incompatible.\n",
      "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.22.4 which is incompatible.\n",
      "albumentations 1.4.20 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
      "arviz 0.20.0 requires scipy>=1.9.0, but you have scipy 1.7.3 which is incompatible.\n",
      "astropy 6.1.7 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "bayesian-optimization 2.0.3 requires numpy>=1.25, but you have numpy 1.22.4 which is incompatible.\n",
      "bigframes 1.29.0 requires matplotlib>=3.7.1, but you have matplotlib 3.5.3 which is incompatible.\n",
      "bigframes 1.29.0 requires numpy>=1.24.0, but you have numpy 1.22.4 which is incompatible.\n",
      "bigframes 1.29.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.22.4 which is incompatible.\n",
      "contourpy 1.3.1 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "cudf-cu12 25.2.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "cuml-cu12 25.2.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "cuml-cu12 25.2.0 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "cuvs-cu12 25.2.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "dask-cuda 25.2.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "dask-cudf-cu12 25.2.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "datasets 3.3.1 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\n",
      "dipy 1.10.0 requires scipy>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "featuretools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.22.4 which is incompatible.\n",
      "featuretools 1.31.0 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.24.4 which is incompatible.\n",
      "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\n",
      "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.22.4 which is incompatible.\n",
      "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
      "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
      "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "kaggle-environments 1.16.11 requires scipy>=1.11.2, but you have scipy 1.7.3 which is incompatible.\n",
      "langchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\n",
      "libpysal 4.9.2 requires scipy>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "mizani 0.13.1 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
      "mizani 0.13.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.22.4 which is incompatible.\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.22.4 which is incompatible.\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.22.4 which is incompatible.\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "mne 1.9.0 requires matplotlib>=3.6, but you have matplotlib 3.5.3 which is incompatible.\n",
      "mne 1.9.0 requires numpy<3,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "mne 1.9.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
      "nilearn 0.10.4 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "numexpr 2.10.2 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
      "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
      "plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.5.3 which is incompatible.\n",
      "plotnine 0.14.4 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
      "plotnine 0.14.4 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "pyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.22.4 which is incompatible.\n",
      "pylibraft-cu12 25.2.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.22.4 which is incompatible.\n",
      "pywavelets 1.8.0 requires numpy<3,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "rmm-cu12 25.2.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "scikit-image 0.25.0 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
      "scikit-image 0.25.0 requires scipy>=1.11.2, but you have scipy 1.7.3 which is incompatible.\n",
      "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "stumpy 1.13.0 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.4 which is incompatible.\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\n",
      "ucx-py-cu12 0.42.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "ucxx-cu12 0.42.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "visions 0.7.6 requires numpy>=1.23.2, but you have numpy 1.22.4 which is incompatible.\n",
      "woodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.22.4 which is incompatible.\n",
      "woodwork 0.31.0 requires scikit-learn>=1.1.0, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "woodwork 0.31.0 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "xarray 2024.11.0 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
      "xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
      "xarray-einstats 0.8.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed appdirs-1.4.4 bidirectional-cross-attention-0.0.4 cycler-0.11.0 einops-0.6.1 fonttools-4.38.0 gitpython-3.1.41 importlib-metadata-6.7.0 jaxtyping-0.2.12 joblib-1.3.2 kornia-0.6.12 lpips-0.1.4 matplotlib-3.5.3 numpy-1.22.4 opencv-python-4.9.0.80 packaging-23.2 plyfile-0.8.1 prettytable-3.7.0 protobuf-4.24.4 psutil-5.9.7 pyparsing-3.1.1 python-dateutil-2.8.2 pytorch-fid-0.3.0 pyyaml-6.0.1 scikit-learn-1.0.2 scipy-1.7.3 sentry-sdk-1.39.2 setproctitle-1.3.3 six-1.16.0 threadpoolctl-3.1.0 torch-scatter-2.1.1 tqdm-4.66.1 typeguard-4.1.2 wandb-0.16.2 zipp-3.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install appdirs==1.4.4 bidirectional-cross-attention==0.0.4 click==8.1.7 colorama==0.4.6 cycler==0.11.0 docker-pycreds==0.4.0 einops==0.6.1 fonttools==4.38.0 gitdb==4.0.11 gitpython==3.1.41 importlib-metadata==6.7.0 jaxtyping==0.2.12 joblib==1.3.2 kornia==0.6.12 lpips==0.1.4 matplotlib==3.5.3 opencv-python==4.9.0.80 packaging==23.2 plyfile==0.8.1 prettytable==3.7.0 protobuf==4.24.4 psutil==5.9.7 pyparsing==3.1.1 python-dateutil==2.8.2 pytorch-fid==0.3.0 pyyaml==6.0.1 scikit-learn==1.0.2 scipy==1.7.3 sentry-sdk==1.39.2 setproctitle==1.3.3 six==1.16.0 smmap==5.0.1 threadpoolctl==3.1.0 torch-scatter==2.1.1 tqdm==4.66.1 typeguard==4.1.2 wandb==0.16.2 wcwidth==0.2.13 zipp==3.15.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T20:30:22.639814Z",
     "iopub.status.busy": "2025-04-05T20:30:22.639540Z",
     "iopub.status.idle": "2025-04-05T20:33:43.742067Z",
     "shell.execute_reply": "2025-04-05T20:33:43.741011Z",
     "shell.execute_reply.started": "2025-04-05T20:30:22.639780Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///kaggle/working/GScream/submodules/diff-gaussian-rasterization\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Installing collected packages: diff_gaussian_rasterization\n",
      "  Running setup.py develop for diff_gaussian_rasterization\n",
      "Successfully installed diff_gaussian_rasterization-0.0.0\n",
      "Obtaining file:///kaggle/working/GScream/submodules/simple-knn\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Installing collected packages: simple_knn\n",
      "  Running setup.py develop for simple_knn\n",
      "Successfully installed simple_knn-0.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -e submodules/diff-gaussian-rasterization\n",
    "!pip install -e submodules/simple-knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T20:33:43.743457Z",
     "iopub.status.busy": "2025-04-05T20:33:43.743100Z",
     "iopub.status.idle": "2025-04-05T20:33:50.661043Z",
     "shell.execute_reply": "2025-04-05T20:33:50.660180Z",
     "shell.execute_reply.started": "2025-04-05T20:33:43.743425Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.23.0\n",
      "  Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.4\n",
      "    Uninstalling numpy-1.22.4:\n",
      "      Successfully uninstalled numpy-1.22.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cartopy 0.24.1 requires matplotlib>=3.6, but you have matplotlib 3.5.3 which is incompatible.\n",
      "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.0 which is incompatible.\n",
      "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.0 which is incompatible.\n",
      "albumentations 1.4.20 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "arviz 0.20.0 requires scipy>=1.9.0, but you have scipy 1.7.3 which is incompatible.\n",
      "bayesian-optimization 2.0.3 requires numpy>=1.25, but you have numpy 1.23.0 which is incompatible.\n",
      "bigframes 1.29.0 requires matplotlib>=3.7.1, but you have matplotlib 3.5.3 which is incompatible.\n",
      "bigframes 1.29.0 requires numpy>=1.24.0, but you have numpy 1.23.0 which is incompatible.\n",
      "bigframes 1.29.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.23.0 which is incompatible.\n",
      "cuml-cu12 25.2.0 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "datasets 3.3.1 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\n",
      "dipy 1.10.0 requires scipy>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "featuretools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.23.0 which is incompatible.\n",
      "featuretools 1.31.0 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\n",
      "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.23.0 which is incompatible.\n",
      "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.0 which is incompatible.\n",
      "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.0 which is incompatible.\n",
      "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "kaggle-environments 1.16.11 requires scipy>=1.11.2, but you have scipy 1.7.3 which is incompatible.\n",
      "langchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\n",
      "libpysal 4.9.2 requires scipy>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "mizani 0.13.1 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n",
      "mizani 0.13.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.23.0 which is incompatible.\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.23.0 which is incompatible.\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.23.0 which is incompatible.\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "mne 1.9.0 requires matplotlib>=3.6, but you have matplotlib 3.5.3 which is incompatible.\n",
      "mne 1.9.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
      "nilearn 0.10.4 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n",
      "plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.5.3 which is incompatible.\n",
      "plotnine 0.14.4 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n",
      "plotnine 0.14.4 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "pyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.0 which is incompatible.\n",
      "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.23.0 which is incompatible.\n",
      "scikit-image 0.25.0 requires numpy>=1.24, but you have numpy 1.23.0 which is incompatible.\n",
      "scikit-image 0.25.0 requires scipy>=1.11.2, but you have scipy 1.7.3 which is incompatible.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.0 which is incompatible.\n",
      "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "stumpy 1.13.0 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.23.0 which is incompatible.\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\n",
      "visions 0.7.6 requires numpy>=1.23.2, but you have numpy 1.23.0 which is incompatible.\n",
      "woodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.23.0 which is incompatible.\n",
      "woodwork 0.31.0 requires scikit-learn>=1.1.0, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "woodwork 0.31.0 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "xarray 2024.11.0 requires numpy>=1.24, but you have numpy 1.23.0 which is incompatible.\n",
      "xarray-einstats 0.8.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.23.0 --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T20:33:50.662223Z",
     "iopub.status.busy": "2025-04-05T20:33:50.661965Z",
     "iopub.status.idle": "2025-04-05T20:35:00.049108Z",
     "shell.execute_reply": "2025-04-05T20:35:00.048185Z",
     "shell.execute_reply.started": "2025-04-05T20:33:50.662183Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.24.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.8/644.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, tensorboard, ml-dtypes, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.0\n",
      "    Uninstalling numpy-1.23.0:\n",
      "      Successfully uninstalled numpy-1.23.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.17.1\n",
      "    Uninstalling tensorboard-2.17.1:\n",
      "      Successfully uninstalled tensorboard-2.17.1\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.4.1\n",
      "    Uninstalling ml-dtypes-0.4.1:\n",
      "      Successfully uninstalled ml-dtypes-0.4.1\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.17.1\n",
      "    Uninstalling tensorflow-2.17.1:\n",
      "      Successfully uninstalled tensorflow-2.17.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cartopy 0.24.1 requires matplotlib>=3.6, but you have matplotlib 3.5.3 which is incompatible.\n",
      "albumentations 1.4.20 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "arviz 0.20.0 requires scipy>=1.9.0, but you have scipy 1.7.3 which is incompatible.\n",
      "bigframes 1.29.0 requires matplotlib>=3.7.1, but you have matplotlib 3.5.3 which is incompatible.\n",
      "bigframes 1.29.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "catboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.1.3 which is incompatible.\n",
      "cuml-cu12 25.2.0 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.1.3 which is incompatible.\n",
      "datasets 3.3.1 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\n",
      "dipy 1.10.0 requires scipy>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "featuretools 1.31.0 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.3 which is incompatible.\n",
      "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "kaggle-environments 1.16.11 requires scipy>=1.11.2, but you have scipy 1.7.3 which is incompatible.\n",
      "langchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\n",
      "langchain 0.3.12 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.1.3 which is incompatible.\n",
      "libpysal 4.9.2 requires scipy>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "mizani 0.13.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.1.3 which is incompatible.\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.1.3 which is incompatible.\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.1.3 which is incompatible.\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "mne 1.9.0 requires matplotlib>=3.6, but you have matplotlib 3.5.3 which is incompatible.\n",
      "mne 1.9.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
      "nilearn 0.10.4 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.5.3 which is incompatible.\n",
      "plotnine 0.14.4 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.1.3 which is incompatible.\n",
      "scikit-image 0.25.0 requires scipy>=1.11.2, but you have scipy 1.7.3 which is incompatible.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 2.1.3 which is incompatible.\n",
      "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "stumpy 1.13.0 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.19.0 which is incompatible.\n",
      "tensorflow-text 2.17.0 requires tensorflow<2.18,>=2.17.0, but you have tensorflow 2.19.0 which is incompatible.\n",
      "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.19.0 which is incompatible.\n",
      "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.3 which is incompatible.\n",
      "woodwork 0.31.0 requires scikit-learn>=1.1.0, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "woodwork 0.31.0 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "xarray-einstats 0.8.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed ml-dtypes-0.5.1 numpy-2.1.3 tensorboard-2.19.0 tensorflow-2.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy tensorflow tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T20:35:00.050551Z",
     "iopub.status.busy": "2025-04-05T20:35:00.050163Z",
     "iopub.status.idle": "2025-04-05T20:35:10.934207Z",
     "shell.execute_reply": "2025-04-05T20:35:10.933104Z",
     "shell.execute_reply.started": "2025-04-05T20:35:00.050525Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.0.0\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cartopy 0.24.1 requires matplotlib>=3.6, but you have matplotlib 3.5.3 which is incompatible.\n",
      "albumentations 1.4.20 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "arviz 0.20.0 requires scipy>=1.9.0, but you have scipy 1.7.3 which is incompatible.\n",
      "bigframes 1.29.0 requires matplotlib>=3.7.1, but you have matplotlib 3.5.3 which is incompatible.\n",
      "bigframes 1.29.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "cuml-cu12 25.2.0 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "datasets 3.3.1 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\n",
      "dipy 1.10.0 requires scipy>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "featuretools 1.31.0 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.66.1 which is incompatible.\n",
      "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "kaggle-environments 1.16.11 requires scipy>=1.11.2, but you have scipy 1.7.3 which is incompatible.\n",
      "langchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\n",
      "libpysal 4.9.2 requires scipy>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "mizani 0.13.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "mne 1.9.0 requires matplotlib>=3.6, but you have matplotlib 3.5.3 which is incompatible.\n",
      "mne 1.9.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
      "nilearn 0.10.4 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.5.3 which is incompatible.\n",
      "plotnine 0.14.4 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "scikit-image 0.25.0 requires scipy>=1.11.2, but you have scipy 1.7.3 which is incompatible.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.26.4 which is incompatible.\n",
      "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
      "stumpy 1.13.0 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.19.0 which is incompatible.\n",
      "tensorflow-text 2.17.0 requires tensorflow<2.18,>=2.17.0, but you have tensorflow 2.19.0 which is incompatible.\n",
      "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.19.0 which is incompatible.\n",
      "woodwork 0.31.0 requires scikit-learn>=1.1.0, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "woodwork 0.31.0 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
      "xarray-einstats 0.8.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2.0.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T20:35:10.937381Z",
     "iopub.status.busy": "2025-04-05T20:35:10.937114Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./refs/2_out.png\n",
      "./refs/2_out_pred.npy\n",
      "/usr/local/lib/python3.10/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|█████████████████████████████████████████| 528M/528M [00:02<00:00, 212MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)\n",
      "2025-04-05 20:35:26.372107: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743885326.392616     473 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743885326.398830     473 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743885326.418884     473 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743885326.418910     473 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743885326.418914     473 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743885326.418917     473 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-05 20:35:32,009 - INFO: args: Namespace(sh_degree=3, feat_dim=32, n_offsets=10, voxel_size=0.005, update_depth=3, update_init_factor=16, update_hierachy_factor=4, use_feat_bank=False, source_path='/kaggle/input/spinnerf-dataset-processed/spinnerf_dataset_processed/2', model_path='outputs/spinnerf_dataset/2/gscream/', pretrained_model_path='', images='images', resolution=-1, white_background=False, data_device='cuda', eval=True, lod=0, specified_ply_path='/kaggle/input/spinnerf-dataset-processed/spinnerf_dataset_processed/2/sparse/0/points3D.ply', load_mask=True, load_depth=True, load_norm=True, load_midas=False, is_spin=True, is_ibr=False, ref_image_path='./refs/2_out.png', ref_depth_path='./refs/2_out_pred.npy', ref_normal_path='', ref_mask_path='', iterations=30000, position_lr_init=0.0, position_lr_final=0.0, position_lr_delay_mult=0.01, position_lr_max_steps=30000, offset_lr_init=0.01, offset_lr_final=0.0001, offset_lr_delay_mult=0.01, offset_lr_max_steps=30000, feature_lr=0.0075, opacity_lr=0.02, uncertainty_lr=0.0, scaling_lr=0.007, rotation_lr=0.002, mlp_opacity_lr_init=0.002, mlp_opacity_lr_final=2e-05, mlp_opacity_lr_delay_mult=0.01, mlp_opacity_lr_max_steps=30000, mlp_uncertainty_lr_init=0.002, mlp_uncertainty_lr_final=2e-05, mlp_uncertainty_lr_delay_mult=0.01, mlp_uncertainty_lr_max_steps=30000, mlp_cov_lr_init=0.004, mlp_cov_lr_final=0.004, mlp_cov_lr_delay_mult=0.01, mlp_cov_lr_max_steps=30000, mlp_color_lr_init=0.008, mlp_color_lr_final=5e-05, mlp_color_lr_delay_mult=0.01, mlp_color_lr_max_steps=30000, mlp_featurebank_lr_init=0.01, mlp_featurebank_lr_final=1e-05, mlp_featurebank_lr_delay_mult=0.01, mlp_featurebank_lr_max_steps=30000, discriminator_lr_init=0.01, discriminator_lr_final=1e-05, discriminator_lr_delay_mult=0.01, discriminator_lr_max_steps=30000, crossattn_lr_init=0.002, crossattn_lr_final=2e-05, crossattn_lr_delay_mult=0.01, crossattn_lr_max_steps=30000, selfattn_lr_init=0.01, selfattn_lr_final=1e-05, selfattn_lr_delay_mult=0.01, selfattn_lr_max_steps=30000, percent_dense=0.01, lambda_dssim=0.2, lambda_depth=1.0, start_stat=500, update_from=1500, update_interval=100, update_until=15000, start_crossattn_from=15000, min_opacity=0.005, success_threshold=0.8, densify_grad_threshold=0.0002, lpips_lr=0.0, lpips_b=20, perceptual_lr=0.0, perceptual_b=2, refer_rgb_lr=1.0, refer_rgb_lr_fg=20.0, other_rgb_lr=1.0, other_rgb_lr_fg=0.0, refer_depth_lr=1.0, refer_depth_lr_fg=100.0, refer_depth_lr_smooth=1.0, refer_depth_lr_smooth_edge=1.0, disp_smooth_lr=1.0, other_depth_lr=0.1, other_depth_lr_smooth=0.1, refer_normal_lr=0.0, other_normal_lr=0.0, refer_opacity_lr=0.0, other_opacity_lr=0.0, flat_lr=1.0, sparse_depth_lr=0.0, refer_warping_lr=0.0, vgg_lr=0.0, discriminator_lr=0.0, crossattn_lr=0.0, adv_lr=0.0, use_lama=False, pretrained_ply='', enable_crossattn_refview=1.0, enable_crossattn_otherview=1.0, attn_head_num=8, attn_head_dim=64, crossattn_feat_update_ema=0.03, enable_pe=0.0, enable_enlarge_samping=0.0, sampling_2D_enlarge_ratio=2.0, enable_edge_samping=1.0, enable_twopatch_samping=0.0, sampling_2D_small_ratio=0.6, enable_selfattn=0.0, selfattn_feat_update_ema=1.0, selfattn_knn_maxnum=2000, selfattn_sampling_rad=0.5, crossattn_start_iter=15000, convert_SHs_python=False, compute_cov3D_python=False, debug=False, ip='127.0.0.1', port=10001, debug_from=-1, detect_anomaly=False, warmup=False, use_wandb=False, test_iterations=[3000, 7000, 30000], save_iterations=[3000, 7000, 30000, 30000], quiet=False, checkpoint_iterations=[], start_checkpoint=None, gpu='0')\n",
      "2025-04-05 20:35:32,011 - INFO: using GPU 0\n",
      "2025-04-05 20:35:32,011 - INFO: save code failed~\n",
      "2025-04-05 20:35:32,011 - INFO: Optimizing outputs/spinnerf_dataset/2/gscream/\n",
      "Training progress:  10%| | 3000/30000 [06:58<1:35:09,  4.73it/s, Loss=0.1322804]2025-04-05 20:43:38,587 - INFO: \n",
      "[ITER 3000] Evaluating test: L1 0.08796699363738299 PSNR 19.093782424926758\n",
      "2025-04-05 20:43:44,964 - INFO: \n",
      "[ITER 3000] Evaluating train: L1 0.06833097040653228 PSNR 20.118925857543946\n",
      "2025-04-05 20:43:45,041 - INFO: \n",
      "[ITER 3000] Saving Gaussians\n",
      "Training progress:  23%|▏| 7000/30000 [28:05<1:52:26,  3.41it/s, Loss=0.1317014]2025-04-05 21:04:33,011 - INFO: \n",
      "[ITER 7000] Evaluating test: L1 0.08830082658678294 PSNR 19.02569098472595\n",
      "2025-04-05 21:04:37,208 - INFO: \n",
      "[ITER 7000] Evaluating train: L1 0.06584083884954453 PSNR 20.447855758666993\n",
      "2025-04-05 21:04:37,291 - INFO: \n",
      "[ITER 7000] Saving Gaussians\n",
      "Training progress: 100%|█| 30000/30000 [3:15:20<00:00,  2.56it/s, Loss=0.1291017\n",
      "2025-04-05 23:51:50,064 - INFO: \n",
      "[ITER 30000] Evaluating test: L1 0.08844871427863837 PSNR 18.914941787719727\n",
      "2025-04-05 23:51:54,624 - INFO: \n",
      "[ITER 30000] Evaluating train: L1 0.06374008506536484 PSNR 20.6068058013916\n",
      "2025-04-05 23:51:54,692 - INFO: \n",
      "[ITER 30000] Saving Gaussians\n",
      "2025-04-05 23:52:06,938 - INFO: \n",
      "Training complete.\n",
      "2025-04-05 23:52:06,939 - INFO: \n",
      "Starting Rendering~\n",
      "/kaggle/working/GScream/scene/gaussian_model.py:994: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n",
      "Rendering progress: 100%|█████████████████████| 120/120 [02:59<00:00,  1.49s/it]\n",
      "sh: 1: /usr/local/bin/ffmpeg: not found\n",
      "2025-04-05 23:55:28,106 - INFO: Spiral FPS: \u001b[1;35m8.70116\u001b[0m\n",
      "Rendering progress: 100%|███████████████████████| 60/60 [01:04<00:00,  1.08s/it]\n",
      "2025-04-05 23:56:32,843 - INFO: Train FPS: \u001b[1;35m8.43665\u001b[0m\n",
      "Rendering progress: 100%|███████████████████████| 40/40 [00:44<00:00,  1.11s/it]\n",
      "2025-04-05 23:57:17,049 - INFO: Test FPS: \u001b[1;35m8.82728\u001b[0m\n",
      "2025-04-05 23:57:17,102 - INFO: \n",
      "Rendering complete.\n",
      "2025-04-05 23:57:17,103 - INFO: \n",
      " Starting evaluation...\n",
      "Metric evaluation progress: 100%|███████████████| 40/40 [00:13<00:00,  2.87it/s]\n",
      "2025-04-05 23:57:33,655 - INFO: model_paths: \u001b[1;35moutputs/spinnerf_dataset/2/gscream/\u001b[0m\n",
      "2025-04-05 23:57:33,656 - INFO:   SSIM : \u001b[1;35m   0.4876769\u001b[0m\n",
      "2025-04-05 23:57:33,657 - INFO:   PSNR : \u001b[1;35m  18.9145222\u001b[0m\n",
      "2025-04-05 23:57:33,658 - INFO:   LPIPS: \u001b[1;35m   0.3463262\u001b[0m\n",
      "2025-04-05 23:57:33,659 - INFO:   masked SSIM : \u001b[1;35m   0.1456043\u001b[0m\n",
      "2025-04-05 23:57:33,659 - INFO:   masked PSNR : \u001b[1;35m  15.4255581\u001b[0m\n",
      "2025-04-05 23:57:33,660 - INFO:   masked LPIPS: \u001b[1;35m   0.5690845\u001b[0m\n",
      "2025-04-05 23:57:33,667 - INFO: \n",
      "Evaluating complete.\n",
      "./refs/3_out.png\n",
      "./refs/3_out_pred.npy\n",
      "/usr/local/lib/python3.10/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.10/dist-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)\n",
      "2025-04-05 23:57:46.754844: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743897466.774159     505 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743897466.780428     505 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743897466.803401     505 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743897466.803441     505 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743897466.803445     505 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743897466.803449     505 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-05 23:57:49,695 - INFO: args: Namespace(sh_degree=3, feat_dim=32, n_offsets=10, voxel_size=0.005, update_depth=3, update_init_factor=16, update_hierachy_factor=4, use_feat_bank=False, source_path='/kaggle/input/spinnerf-dataset-processed/spinnerf_dataset_processed/3', model_path='outputs/spinnerf_dataset/3/gscream/', pretrained_model_path='', images='images', resolution=-1, white_background=False, data_device='cuda', eval=True, lod=0, specified_ply_path='/kaggle/input/spinnerf-dataset-processed/spinnerf_dataset_processed/3/sparse/0/points3D.ply', load_mask=True, load_depth=True, load_norm=True, load_midas=False, is_spin=True, is_ibr=False, ref_image_path='./refs/3_out.png', ref_depth_path='./refs/3_out_pred.npy', ref_normal_path='', ref_mask_path='', iterations=30000, position_lr_init=0.0, position_lr_final=0.0, position_lr_delay_mult=0.01, position_lr_max_steps=30000, offset_lr_init=0.01, offset_lr_final=0.0001, offset_lr_delay_mult=0.01, offset_lr_max_steps=30000, feature_lr=0.0075, opacity_lr=0.02, uncertainty_lr=0.0, scaling_lr=0.007, rotation_lr=0.002, mlp_opacity_lr_init=0.002, mlp_opacity_lr_final=2e-05, mlp_opacity_lr_delay_mult=0.01, mlp_opacity_lr_max_steps=30000, mlp_uncertainty_lr_init=0.002, mlp_uncertainty_lr_final=2e-05, mlp_uncertainty_lr_delay_mult=0.01, mlp_uncertainty_lr_max_steps=30000, mlp_cov_lr_init=0.004, mlp_cov_lr_final=0.004, mlp_cov_lr_delay_mult=0.01, mlp_cov_lr_max_steps=30000, mlp_color_lr_init=0.008, mlp_color_lr_final=5e-05, mlp_color_lr_delay_mult=0.01, mlp_color_lr_max_steps=30000, mlp_featurebank_lr_init=0.01, mlp_featurebank_lr_final=1e-05, mlp_featurebank_lr_delay_mult=0.01, mlp_featurebank_lr_max_steps=30000, discriminator_lr_init=0.01, discriminator_lr_final=1e-05, discriminator_lr_delay_mult=0.01, discriminator_lr_max_steps=30000, crossattn_lr_init=0.002, crossattn_lr_final=2e-05, crossattn_lr_delay_mult=0.01, crossattn_lr_max_steps=30000, selfattn_lr_init=0.01, selfattn_lr_final=1e-05, selfattn_lr_delay_mult=0.01, selfattn_lr_max_steps=30000, percent_dense=0.01, lambda_dssim=0.2, lambda_depth=1.0, start_stat=500, update_from=1500, update_interval=100, update_until=15000, start_crossattn_from=15000, min_opacity=0.005, success_threshold=0.8, densify_grad_threshold=0.0002, lpips_lr=0.0, lpips_b=20, perceptual_lr=0.0, perceptual_b=2, refer_rgb_lr=1.0, refer_rgb_lr_fg=20.0, other_rgb_lr=1.0, other_rgb_lr_fg=0.0, refer_depth_lr=1.0, refer_depth_lr_fg=100.0, refer_depth_lr_smooth=1.0, refer_depth_lr_smooth_edge=1.0, disp_smooth_lr=1.0, other_depth_lr=0.1, other_depth_lr_smooth=0.1, refer_normal_lr=0.0, other_normal_lr=0.0, refer_opacity_lr=0.0, other_opacity_lr=0.0, flat_lr=1.0, sparse_depth_lr=0.0, refer_warping_lr=0.0, vgg_lr=0.0, discriminator_lr=0.0, crossattn_lr=0.0, adv_lr=0.0, use_lama=False, pretrained_ply='', enable_crossattn_refview=1.0, enable_crossattn_otherview=1.0, attn_head_num=8, attn_head_dim=64, crossattn_feat_update_ema=0.03, enable_pe=0.0, enable_enlarge_samping=0.0, sampling_2D_enlarge_ratio=2.0, enable_edge_samping=1.0, enable_twopatch_samping=0.0, sampling_2D_small_ratio=0.6, enable_selfattn=0.0, selfattn_feat_update_ema=1.0, selfattn_knn_maxnum=2000, selfattn_sampling_rad=0.5, crossattn_start_iter=15000, convert_SHs_python=False, compute_cov3D_python=False, debug=False, ip='127.0.0.1', port=10001, debug_from=-1, detect_anomaly=False, warmup=False, use_wandb=False, test_iterations=[3000, 7000, 30000], save_iterations=[3000, 7000, 30000, 30000], quiet=False, checkpoint_iterations=[], start_checkpoint=None, gpu='0')\n",
      "2025-04-05 23:57:49,698 - INFO: using GPU 0\n",
      "2025-04-05 23:57:49,698 - INFO: save code failed~\n",
      "2025-04-05 23:57:49,698 - INFO: Optimizing outputs/spinnerf_dataset/3/gscream/\n",
      "Training progress:  10%| | 3000/30000 [05:36<1:20:31,  5.59it/s, Loss=0.1312563]2025-04-06 00:04:32,140 - INFO: \n",
      "[ITER 3000] Evaluating test: L1 0.08962682168930769 PSNR 17.61421778202057\n",
      "2025-04-06 00:04:38,468 - INFO: \n",
      "[ITER 3000] Evaluating train: L1 0.0915407031774521 PSNR 16.64543914794922\n",
      "2025-04-06 00:04:38,518 - INFO: \n",
      "[ITER 3000] Saving Gaussians\n",
      "Training progress:  23%|▏| 7000/30000 [24:53<1:47:28,  3.57it/s, Loss=0.1255650]2025-04-06 00:23:38,333 - INFO: \n",
      "[ITER 7000] Evaluating test: L1 0.08759422339498997 PSNR 17.825778818130495\n",
      "2025-04-06 00:23:42,950 - INFO: \n",
      "[ITER 7000] Evaluating train: L1 0.08731002509593964 PSNR 16.67275619506836\n",
      "2025-04-06 00:23:43,020 - INFO: \n",
      "[ITER 7000] Saving Gaussians\n",
      "Training progress: 100%|█| 30000/30000 [2:51:33<00:00,  2.91it/s, Loss=0.1195824\n",
      "2025-04-06 02:50:18,680 - INFO: \n",
      "[ITER 30000] Evaluating test: L1 0.08560043256729842 PSNR 17.979712057113648\n",
      "2025-04-06 02:50:23,017 - INFO: \n",
      "[ITER 30000] Evaluating train: L1 0.08201093375682832 PSNR 17.03889503479004\n",
      "2025-04-06 02:50:23,075 - INFO: \n",
      "[ITER 30000] Saving Gaussians\n",
      "2025-04-06 02:50:36,415 - INFO: \n",
      "Training complete.\n",
      "2025-04-06 02:50:36,415 - INFO: \n",
      "Starting Rendering~\n",
      "/kaggle/working/GScream/scene/gaussian_model.py:994: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n",
      "Rendering progress: 100%|█████████████████████| 120/120 [02:49<00:00,  1.41s/it]\n",
      "sh: 1: /usr/local/bin/ffmpeg: not found\n",
      "2025-04-06 02:53:48,991 - INFO: Spiral FPS: \u001b[1;35m9.92150\u001b[0m\n",
      "Rendering progress: 100%|███████████████████████| 60/60 [01:10<00:00,  1.17s/it]\n",
      "2025-04-06 02:54:59,312 - INFO: Train FPS: \u001b[1;35m9.27003\u001b[0m\n",
      "Rendering progress: 100%|███████████████████████| 40/40 [00:45<00:00,  1.15s/it]\n",
      "2025-04-06 02:55:45,146 - INFO: Test FPS: \u001b[1;35m8.76122\u001b[0m\n",
      "2025-04-06 02:55:45,150 - INFO: \n",
      "Rendering complete.\n",
      "2025-04-06 02:55:45,150 - INFO: \n",
      " Starting evaluation...\n",
      "Metric evaluation progress: 100%|███████████████| 40/40 [00:13<00:00,  2.93it/s]\n",
      "2025-04-06 02:56:01,666 - INFO: model_paths: \u001b[1;35moutputs/spinnerf_dataset/3/gscream/\u001b[0m\n",
      "2025-04-06 02:56:01,668 - INFO:   SSIM : \u001b[1;35m   0.5339879\u001b[0m\n",
      "2025-04-06 02:56:01,668 - INFO:   PSNR : \u001b[1;35m  17.9793644\u001b[0m\n",
      "2025-04-06 02:56:01,669 - INFO:   LPIPS: \u001b[1;35m   0.2472052\u001b[0m\n",
      "2025-04-06 02:56:01,670 - INFO:   masked SSIM : \u001b[1;35m   0.2315352\u001b[0m\n",
      "2025-04-06 02:56:01,671 - INFO:   masked PSNR : \u001b[1;35m  15.5233278\u001b[0m\n",
      "2025-04-06 02:56:01,672 - INFO:   masked LPIPS: \u001b[1;35m   0.3408263\u001b[0m\n",
      "2025-04-06 02:56:01,678 - INFO: \n",
      "Evaluating complete.\n",
      "./refs/4_out.png\n",
      "./refs/4_out_pred.npy\n",
      "/usr/local/lib/python3.10/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.10/dist-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)\n",
      "2025-04-06 02:56:14.224228: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743908174.245915     537 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743908174.253792     537 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743908174.278344     537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743908174.278385     537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743908174.278391     537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743908174.278399     537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-06 02:56:17,103 - INFO: args: Namespace(sh_degree=3, feat_dim=32, n_offsets=10, voxel_size=0.005, update_depth=3, update_init_factor=16, update_hierachy_factor=4, use_feat_bank=False, source_path='/kaggle/input/spinnerf-dataset-processed/spinnerf_dataset_processed/4', model_path='outputs/spinnerf_dataset/4/gscream/', pretrained_model_path='', images='images', resolution=-1, white_background=False, data_device='cuda', eval=True, lod=0, specified_ply_path='/kaggle/input/spinnerf-dataset-processed/spinnerf_dataset_processed/4/sparse/0/points3D.ply', load_mask=True, load_depth=True, load_norm=True, load_midas=False, is_spin=True, is_ibr=False, ref_image_path='./refs/4_out.png', ref_depth_path='./refs/4_out_pred.npy', ref_normal_path='', ref_mask_path='', iterations=30000, position_lr_init=0.0, position_lr_final=0.0, position_lr_delay_mult=0.01, position_lr_max_steps=30000, offset_lr_init=0.01, offset_lr_final=0.0001, offset_lr_delay_mult=0.01, offset_lr_max_steps=30000, feature_lr=0.0075, opacity_lr=0.02, uncertainty_lr=0.0, scaling_lr=0.007, rotation_lr=0.002, mlp_opacity_lr_init=0.002, mlp_opacity_lr_final=2e-05, mlp_opacity_lr_delay_mult=0.01, mlp_opacity_lr_max_steps=30000, mlp_uncertainty_lr_init=0.002, mlp_uncertainty_lr_final=2e-05, mlp_uncertainty_lr_delay_mult=0.01, mlp_uncertainty_lr_max_steps=30000, mlp_cov_lr_init=0.004, mlp_cov_lr_final=0.004, mlp_cov_lr_delay_mult=0.01, mlp_cov_lr_max_steps=30000, mlp_color_lr_init=0.008, mlp_color_lr_final=5e-05, mlp_color_lr_delay_mult=0.01, mlp_color_lr_max_steps=30000, mlp_featurebank_lr_init=0.01, mlp_featurebank_lr_final=1e-05, mlp_featurebank_lr_delay_mult=0.01, mlp_featurebank_lr_max_steps=30000, discriminator_lr_init=0.01, discriminator_lr_final=1e-05, discriminator_lr_delay_mult=0.01, discriminator_lr_max_steps=30000, crossattn_lr_init=0.002, crossattn_lr_final=2e-05, crossattn_lr_delay_mult=0.01, crossattn_lr_max_steps=30000, selfattn_lr_init=0.01, selfattn_lr_final=1e-05, selfattn_lr_delay_mult=0.01, selfattn_lr_max_steps=30000, percent_dense=0.01, lambda_dssim=0.2, lambda_depth=1.0, start_stat=500, update_from=1500, update_interval=100, update_until=15000, start_crossattn_from=15000, min_opacity=0.005, success_threshold=0.8, densify_grad_threshold=0.0002, lpips_lr=0.0, lpips_b=20, perceptual_lr=0.0, perceptual_b=2, refer_rgb_lr=1.0, refer_rgb_lr_fg=20.0, other_rgb_lr=1.0, other_rgb_lr_fg=0.0, refer_depth_lr=1.0, refer_depth_lr_fg=100.0, refer_depth_lr_smooth=1.0, refer_depth_lr_smooth_edge=1.0, disp_smooth_lr=1.0, other_depth_lr=0.1, other_depth_lr_smooth=0.1, refer_normal_lr=0.0, other_normal_lr=0.0, refer_opacity_lr=0.0, other_opacity_lr=0.0, flat_lr=1.0, sparse_depth_lr=0.0, refer_warping_lr=0.0, vgg_lr=0.0, discriminator_lr=0.0, crossattn_lr=0.0, adv_lr=0.0, use_lama=False, pretrained_ply='', enable_crossattn_refview=1.0, enable_crossattn_otherview=1.0, attn_head_num=8, attn_head_dim=64, crossattn_feat_update_ema=0.03, enable_pe=0.0, enable_enlarge_samping=0.0, sampling_2D_enlarge_ratio=2.0, enable_edge_samping=1.0, enable_twopatch_samping=0.0, sampling_2D_small_ratio=0.6, enable_selfattn=0.0, selfattn_feat_update_ema=1.0, selfattn_knn_maxnum=2000, selfattn_sampling_rad=0.5, crossattn_start_iter=15000, convert_SHs_python=False, compute_cov3D_python=False, debug=False, ip='127.0.0.1', port=10001, debug_from=-1, detect_anomaly=False, warmup=False, use_wandb=False, test_iterations=[3000, 7000, 30000], save_iterations=[3000, 7000, 30000, 30000], quiet=False, checkpoint_iterations=[], start_checkpoint=None, gpu='0')\n",
      "2025-04-06 02:56:17,104 - INFO: using GPU 0\n",
      "2025-04-06 02:56:17,104 - INFO: save code failed~\n",
      "2025-04-06 02:56:17,105 - INFO: Optimizing outputs/spinnerf_dataset/4/gscream/\n",
      "Training progress:  10%| | 3000/30000 [05:55<1:11:33,  6.29it/s, Loss=0.0942294]2025-04-06 03:03:16,990 - INFO: \n",
      "[ITER 3000] Evaluating test: L1 0.05613975524902344 PSNR 21.813672828674317\n",
      "2025-04-06 03:03:23,333 - INFO: \n",
      "[ITER 3000] Evaluating train: L1 0.04588137045502663 PSNR 21.5956600189209\n",
      "2025-04-06 03:03:23,407 - INFO: \n",
      "[ITER 3000] Saving Gaussians\n",
      "Training progress:  23%|▏| 7000/30000 [20:06<1:17:06,  4.97it/s, Loss=0.0839048]2025-04-06 03:17:18,370 - INFO: \n",
      "[ITER 7000] Evaluating test: L1 0.05517421448603273 PSNR 22.084081792831423\n",
      "2025-04-06 03:17:22,857 - INFO: \n",
      "[ITER 7000] Evaluating train: L1 0.04537396207451821 PSNR 21.595857620239258\n",
      "2025-04-06 03:17:22,918 - INFO: \n",
      "[ITER 7000] Saving Gaussians\n",
      "Training progress:  91%|▉| 27270/30000 [1:43:13<10:20,  4.40it/s, Loss=0.0840956\n",
      "2025-04-06 04:39:57,709 - INFO: \n",
      "Training complete.\n",
      "2025-04-06 04:39:57,710 - INFO: \n",
      "Starting Rendering~\n",
      "/kaggle/working/GScream/scene/gaussian_model.py:994: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n",
      "Rendering progress: 100%|█████████████████████| 120/120 [02:58<00:00,  1.49s/it]\n",
      "sh: 1: /usr/local/bin/ffmpeg: not found\n",
      "2025-04-06 04:43:17,727 - INFO: Spiral FPS: \u001b[1;35m19.65761\u001b[0m\n",
      "Rendering progress: 100%|███████████████████████| 60/60 [01:10<00:00,  1.17s/it]\n",
      "2025-04-06 04:44:27,831 - INFO: Train FPS: \u001b[1;35m17.33709\u001b[0m\n",
      "Rendering progress: 100%|███████████████████████| 40/40 [00:43<00:00,  1.08s/it]\n",
      "2025-04-06 04:45:10,966 - INFO: Test FPS: \u001b[1;35m19.92603\u001b[0m\n",
      "2025-04-06 04:45:10,999 - INFO: \n",
      "Rendering complete.\n",
      "2025-04-06 04:45:11,000 - INFO: \n",
      " Starting evaluation...\n",
      "Metric evaluation progress: 100%|███████████████| 40/40 [00:13<00:00,  3.00it/s]\n",
      "2025-04-06 04:45:26,749 - INFO: model_paths: \u001b[1;35moutputs/spinnerf_dataset/4/gscream/\u001b[0m\n",
      "2025-04-06 04:45:26,751 - INFO:   SSIM : \u001b[1;35m   0.5701745\u001b[0m\n",
      "2025-04-06 04:45:26,752 - INFO:   PSNR : \u001b[1;35m  22.0831337\u001b[0m\n",
      "2025-04-06 04:45:26,752 - INFO:   LPIPS: \u001b[1;35m   0.3348828\u001b[0m\n",
      "2025-04-06 04:45:26,753 - INFO:   masked SSIM : \u001b[1;35m   0.4053048\u001b[0m\n",
      "2025-04-06 04:45:26,754 - INFO:   masked PSNR : \u001b[1;35m  21.1257591\u001b[0m\n",
      "2025-04-06 04:45:26,755 - INFO:   masked LPIPS: \u001b[1;35m   0.7118157\u001b[0m\n",
      "2025-04-06 04:45:26,762 - INFO: \n",
      "Evaluating complete.\n",
      "./refs/7_out.png\n",
      "./refs/7_out_pred.npy\n",
      "/usr/local/lib/python3.10/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.10/dist-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)\n",
      "2025-04-06 04:45:38.271976: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743914738.290881     569 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743914738.296613     569 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743914738.314052     569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743914738.314078     569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743914738.314082     569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743914738.314086     569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-06 04:45:40,859 - INFO: args: Namespace(sh_degree=3, feat_dim=32, n_offsets=10, voxel_size=0.005, update_depth=3, update_init_factor=16, update_hierachy_factor=4, use_feat_bank=False, source_path='/kaggle/input/spinnerf-dataset-processed/spinnerf_dataset_processed/7', model_path='outputs/spinnerf_dataset/7/gscream/', pretrained_model_path='', images='images', resolution=-1, white_background=False, data_device='cuda', eval=True, lod=0, specified_ply_path='/kaggle/input/spinnerf-dataset-processed/spinnerf_dataset_processed/7/sparse/0/points3D.ply', load_mask=True, load_depth=True, load_norm=True, load_midas=False, is_spin=True, is_ibr=False, ref_image_path='./refs/7_out.png', ref_depth_path='./refs/7_out_pred.npy', ref_normal_path='', ref_mask_path='', iterations=30000, position_lr_init=0.0, position_lr_final=0.0, position_lr_delay_mult=0.01, position_lr_max_steps=30000, offset_lr_init=0.01, offset_lr_final=0.0001, offset_lr_delay_mult=0.01, offset_lr_max_steps=30000, feature_lr=0.0075, opacity_lr=0.02, uncertainty_lr=0.0, scaling_lr=0.007, rotation_lr=0.002, mlp_opacity_lr_init=0.002, mlp_opacity_lr_final=2e-05, mlp_opacity_lr_delay_mult=0.01, mlp_opacity_lr_max_steps=30000, mlp_uncertainty_lr_init=0.002, mlp_uncertainty_lr_final=2e-05, mlp_uncertainty_lr_delay_mult=0.01, mlp_uncertainty_lr_max_steps=30000, mlp_cov_lr_init=0.004, mlp_cov_lr_final=0.004, mlp_cov_lr_delay_mult=0.01, mlp_cov_lr_max_steps=30000, mlp_color_lr_init=0.008, mlp_color_lr_final=5e-05, mlp_color_lr_delay_mult=0.01, mlp_color_lr_max_steps=30000, mlp_featurebank_lr_init=0.01, mlp_featurebank_lr_final=1e-05, mlp_featurebank_lr_delay_mult=0.01, mlp_featurebank_lr_max_steps=30000, discriminator_lr_init=0.01, discriminator_lr_final=1e-05, discriminator_lr_delay_mult=0.01, discriminator_lr_max_steps=30000, crossattn_lr_init=0.002, crossattn_lr_final=2e-05, crossattn_lr_delay_mult=0.01, crossattn_lr_max_steps=30000, selfattn_lr_init=0.01, selfattn_lr_final=1e-05, selfattn_lr_delay_mult=0.01, selfattn_lr_max_steps=30000, percent_dense=0.01, lambda_dssim=0.2, lambda_depth=1.0, start_stat=500, update_from=1500, update_interval=100, update_until=15000, start_crossattn_from=15000, min_opacity=0.005, success_threshold=0.8, densify_grad_threshold=0.0002, lpips_lr=0.0, lpips_b=20, perceptual_lr=0.0, perceptual_b=2, refer_rgb_lr=1.0, refer_rgb_lr_fg=20.0, other_rgb_lr=1.0, other_rgb_lr_fg=0.0, refer_depth_lr=1.0, refer_depth_lr_fg=100.0, refer_depth_lr_smooth=1.0, refer_depth_lr_smooth_edge=1.0, disp_smooth_lr=1.0, other_depth_lr=0.1, other_depth_lr_smooth=0.1, refer_normal_lr=0.0, other_normal_lr=0.0, refer_opacity_lr=0.0, other_opacity_lr=0.0, flat_lr=1.0, sparse_depth_lr=0.0, refer_warping_lr=0.0, vgg_lr=0.0, discriminator_lr=0.0, crossattn_lr=0.0, adv_lr=0.0, use_lama=False, pretrained_ply='', enable_crossattn_refview=1.0, enable_crossattn_otherview=1.0, attn_head_num=8, attn_head_dim=64, crossattn_feat_update_ema=0.03, enable_pe=0.0, enable_enlarge_samping=0.0, sampling_2D_enlarge_ratio=2.0, enable_edge_samping=1.0, enable_twopatch_samping=0.0, sampling_2D_small_ratio=0.6, enable_selfattn=0.0, selfattn_feat_update_ema=1.0, selfattn_knn_maxnum=2000, selfattn_sampling_rad=0.5, crossattn_start_iter=15000, convert_SHs_python=False, compute_cov3D_python=False, debug=False, ip='127.0.0.1', port=10001, debug_from=-1, detect_anomaly=False, warmup=False, use_wandb=False, test_iterations=[3000, 7000, 30000], save_iterations=[3000, 7000, 30000, 30000], quiet=False, checkpoint_iterations=[], start_checkpoint=None, gpu='0')\n",
      "2025-04-06 04:45:40,861 - INFO: using GPU 0\n",
      "2025-04-06 04:45:40,861 - INFO: save code failed~\n",
      "2025-04-06 04:45:40,861 - INFO: Optimizing outputs/spinnerf_dataset/7/gscream/\n",
      "Training progress:  10%| | 3000/30000 [05:50<1:29:38,  5.02it/s, Loss=0.0868871]2025-04-06 04:52:35,253 - INFO: \n",
      "[ITER 3000] Evaluating test: L1 0.06202827226370573 PSNR 21.227351903915405\n",
      "2025-04-06 04:52:41,210 - INFO: \n",
      "[ITER 3000] Evaluating train: L1 0.05634542405605317 PSNR 20.491361236572267\n",
      "2025-04-06 04:52:41,278 - INFO: \n",
      "[ITER 3000] Saving Gaussians\n",
      "Training progress:  23%|▏| 7000/30000 [26:39<1:52:18,  3.41it/s, Loss=0.0707956]2025-04-06 05:13:13,990 - INFO: \n",
      "[ITER 7000] Evaluating test: L1 0.06103749442845583 PSNR 21.243357849121097\n",
      "2025-04-06 05:13:18,276 - INFO: \n",
      "[ITER 7000] Evaluating train: L1 0.0543780729174614 PSNR 20.496292877197266\n",
      "2025-04-06 05:13:18,349 - INFO: \n",
      "[ITER 7000] Saving Gaussians\n",
      "Training progress:  33%|▎| 9850/30000 [44:39<2:03:12,  2.73it/s, Loss=0.1037825]"
     ]
    }
   ],
   "source": [
    "!python scripts/run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T06:33:44.847804Z",
     "iopub.status.busy": "2025-04-06T06:33:44.847316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Path to the folder you want to zip\n",
    "folder_to_zip = \"/kaggle/working/GScream/outputs\"\n",
    "\n",
    "# Define the output zip file path\n",
    "zip_file_path = \"/kaggle/working/original_part2.zip\"\n",
    "\n",
    "# Create a zip archive of the folder\n",
    "shutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', folder_to_zip)\n",
    "\n",
    "# Now you can download the zip file using the link provided below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide the path to the zip file for download\n",
    "FileLink(\"original_part2.zip\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6628976,
     "sourceId": 10697441,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7035081,
     "sourceId": 11256779,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7043330,
     "sourceId": 11267682,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7045056,
     "sourceId": 11270308,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7051290,
     "sourceId": 11278630,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7051434,
     "sourceId": 11278820,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
